{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "from dt_class import DecisionTree\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_null_values(X, features, null_ratio, random_state=RANDOM_STATE):\n",
    "    X_copied = X.copy()\n",
    "    random.seed(random_state)\n",
    "    for feat in features:\n",
    "        null_indexes = random.sample(range(X.shape[0]), int(round(X.shape[0] * null_ratio)))\n",
    "        X_copied[:, feat][null_indexes] = np.nan\n",
    "    return X_copied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gs_cv(grid, estimators, x_label, y_label, negative=False, filename=None):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(16,6))\n",
    "    \n",
    "    ax1.set_title('Train score')\n",
    "    for lbl, est in estimators.items():\n",
    "        mean = est.cv_results_['mean_train_score']\n",
    "        if negative: mean = mean * -1.0\n",
    "        std = est.cv_results_['std_train_score']\n",
    "        ax1.plot(grid, mean, label=lbl)\n",
    "        ax1.fill_between(grid, mean - std, mean + std, alpha = 0.2)\n",
    "    ax1.set_xlabel(x_label)\n",
    "    ax1.set_ylabel(y_label)\n",
    "    ax1.grid()\n",
    "    ax1.legend()\n",
    "    \n",
    "    ax2.set_title('Test score')\n",
    "    for lbl, est in estimators.items():\n",
    "        mean = est.cv_results_['mean_test_score']\n",
    "        if negative: mean = mean * -1.0\n",
    "        std = est.cv_results_['std_test_score']\n",
    "        ax2.plot(grid, mean, label=lbl)\n",
    "        ax2.fill_between(grid, mean - std, mean + std, alpha = 0.2)\n",
    "    ax2.set_xlabel(x_label)\n",
    "    ax2.set_ylabel(y_label)\n",
    "    ax2.grid()\n",
    "    ax2.legend()\n",
    "    \n",
    "    if filename is not None:\n",
    "        plt.savefig(filename, format='png', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cv_scores(grid, scores, x_label, y_label, negative=False, filename=None):\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    for lbl, s in scores.items():\n",
    "        mean = np.array(s[0])\n",
    "        if negative: mean = mean * -1.0\n",
    "        plt.plot(grid, mean, label=lbl)\n",
    "        plt.fill_between(grid, mean - np.array(s[1]), mean + np.array(s[1]), alpha = 0.2)\n",
    "    plt.title('Cross-validated score')\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    \n",
    "    if filename is not None:\n",
    "        plt.savefig(filename, format='png', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nulls_scores(grid, simple_score, surrogate_score, x_label, y_label, filename=None):\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    plt.plot(grid, simple_score, label='simple splits')\n",
    "    plt.plot(grid, surrogate_score, label='surrogate splits')\n",
    "    plt.title('Test score')\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    \n",
    "    if filename is not None:\n",
    "        plt.savefig(filename, format='png', dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_features=10, n_informative=5, n_redundant=2, n_samples=1000, \n",
    "                           n_clusters_per_class=5, class_sep=1.0, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_param_grid = {'max_depth': range(2, 16)}\n",
    "\n",
    "gscv_params = {'param_grid': gs_param_grid,\n",
    "               'scoring': 'roc_auc', \n",
    "               'cv': 5, \n",
    "               'return_train_score': True, \n",
    "               'n_jobs': -1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_tree = DecisionTreeClassifier(criterion='gini', random_state=RANDOM_STATE)\n",
    "sklearn_gscv = GridSearchCV(estimator=sklearn_tree, **gscv_params)\n",
    "\n",
    "custom_tree = DecisionTree(criterion='gini')\n",
    "custom_gscv = GridSearchCV(estimator=custom_tree, **gscv_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sklearn_gscv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "custom_gscv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gs_cv(grid=gs_param_grid['max_depth'], \n",
    "           estimators={'sklearn (gini)': sklearn_gscv, 'custom (gini)': custom_gscv}, \n",
    "           x_label='max_depth', y_label='roc_auc',\n",
    "           filename='./img/comparsion_gini.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_tree = DecisionTreeClassifier(criterion='entropy', random_state=RANDOM_STATE)\n",
    "sklearn_gscv = GridSearchCV(estimator=sklearn_tree, **gscv_params)\n",
    "\n",
    "custom_tree = DecisionTree(criterion='entropy')\n",
    "custom_gscv = GridSearchCV(estimator=custom_tree, **gscv_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sklearn_gscv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "custom_gscv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gs_cv(grid=gs_param_grid['max_depth'], \n",
    "           estimators={'sklearn (entropy)': sklearn_gscv, 'custom (entropy)': custom_gscv}, \n",
    "           x_label='max_depth', y_label='roc_auc', \n",
    "           filename='./img/comparsion_entropy.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_tree_simple = DecisionTree(criterion='gini', max_depth=7, use_surrogate_splits=False)\n",
    "custom_tree_surrogate = DecisionTree(criterion='gini', max_depth=7, use_surrogate_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "null_ratios = np.arange(0.0, 0.55, 0.05)\n",
    "\n",
    "means_simple, means_surrogate = [], []\n",
    "stds_simple, stds_surrogate = [], []\n",
    "\n",
    "for null_ratio in null_ratios:\n",
    "    X_nulls = insert_null_values(X, features=range(10), null_ratio=null_ratio)\n",
    "    \n",
    "    score_simple = cross_val_score(custom_tree_simple, X_nulls, y, scoring='roc_auc', cv=5, n_jobs=-1)\n",
    "    means_simple.append(np.mean(score_simple))\n",
    "    stds_simple.append(np.std(score_simple))\n",
    "    \n",
    "    score_surrogate = cross_val_score(custom_tree_surrogate, X_nulls, y, scoring='roc_auc', cv=5, n_jobs=-1)\n",
    "    means_surrogate.append(np.mean(score_surrogate))\n",
    "    stds_surrogate.append(np.std(score_surrogate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cv_scores(grid=null_ratios, \n",
    "               scores={'simple splits': (means_simple, stds_simple), \n",
    "                       'surrogate splits': (means_surrogate, stds_surrogate)}, \n",
    "               x_label='Null values ratio', y_label='roc_auc',\n",
    "               filename='./img/missing_classification.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### missing only test values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "custom_tree_simple.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "custom_tree_surrogate.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores_simple = []\n",
    "test_scores_surrogate = []\n",
    "\n",
    "for null_ratio in null_ratios:\n",
    "    X_test_nulls = insert_null_values(X_test, features=range(10), null_ratio=null_ratio)\n",
    "    test_scores_simple.append(roc_auc_score(y_test, custom_tree_simple.predict_proba(X_test_nulls)[:, 1]))\n",
    "    test_scores_surrogate.append(roc_auc_score(y_test, custom_tree_surrogate.predict_proba(X_test_nulls)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_nulls_scores(null_ratios, test_scores_simple, test_scores_surrogate, \n",
    "                  x_label='Null values ratio', y_label='roc_auc', filename='./img/test_missing_classification.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regression test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_features=10, n_informative=7, n_samples=1000, \n",
    "                       noise=0.05 ,random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_param_grid = {'max_depth': range(2, 16)}\n",
    "\n",
    "gscv_params = {'param_grid': gs_param_grid,\n",
    "               'scoring': 'neg_mean_squared_error', \n",
    "               'cv': 5, \n",
    "               'return_train_score': True, \n",
    "               'n_jobs': -1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_tree = DecisionTreeRegressor(criterion='mse', random_state=RANDOM_STATE)\n",
    "sklearn_gscv = GridSearchCV(estimator=sklearn_tree, **gscv_params)\n",
    "\n",
    "custom_v_tree = DecisionTree(criterion='variance')\n",
    "custom_v_gscv = GridSearchCV(estimator=custom_v_tree, **gscv_params)\n",
    "\n",
    "custom_mm_tree = DecisionTree(criterion='mad_median')\n",
    "custom_mm_gscv = GridSearchCV(estimator=custom_mm_tree, **gscv_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sklearn_gscv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "custom_v_gscv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "custom_mm_gscv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_gs_cv(grid=gs_param_grid['max_depth'], \n",
    "           estimators={'sklearn (MSE)': sklearn_gscv, \n",
    "                       'custom (variance)': custom_v_gscv, \n",
    "                       'custom (mad_median)': custom_mm_gscv}, \n",
    "           x_label='max_depth', y_label='MSE',\n",
    "           negative=True,\n",
    "           filename='./img/comparsion_regression.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_tree_simple = DecisionTree(criterion='variance', max_depth=8, use_surrogate_splits=False)\n",
    "custom_tree_surrogate = DecisionTree(criterion='variance', max_depth=8, use_surrogate_splits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "null_ratios = np.arange(0.0, 0.55, 0.05)\n",
    "\n",
    "means_simple, means_surrogate = [], []\n",
    "stds_simple, stds_surrogate = [], []\n",
    "\n",
    "for null_ratio in null_ratios:\n",
    "    X_nulls = insert_null_values(X, features=range(10), null_ratio=null_ratio)\n",
    "    \n",
    "    score_simple = cross_val_score(custom_tree_simple, X_nulls, y, \n",
    "                                   scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
    "    means_simple.append(np.mean(score_simple))\n",
    "    stds_simple.append(np.std(score_simple))\n",
    "    \n",
    "    score_surrogate = cross_val_score(custom_tree_surrogate, X_nulls, y, \n",
    "                                      scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
    "    means_surrogate.append(np.mean(score_surrogate))\n",
    "    stds_surrogate.append(np.std(score_surrogate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cv_scores(grid=null_ratios, \n",
    "               scores={'simple splits': (means_simple, stds_simple), \n",
    "                       'surrogate splits': (means_surrogate, stds_surrogate)}, \n",
    "               x_label='Null values ratio', y_label='MSE',\n",
    "               negative=True,\n",
    "               filename='./img/missing_regression.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### missing only test values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "custom_tree_simple.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "custom_tree_surrogate.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores_simple = []\n",
    "test_scores_surrogate = []\n",
    "\n",
    "for null_ratio in null_ratios:\n",
    "    X_test_nulls = insert_null_values(X_test, features=range(10), null_ratio=null_ratio)\n",
    "    test_scores_simple.append(mean_squared_error(y_test, custom_tree_simple.predict(X_test_nulls)))\n",
    "    test_scores_surrogate.append(mean_squared_error(y_test, custom_tree_surrogate.predict(X_test_nulls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_nulls_scores(null_ratios, test_scores_simple, test_scores_surrogate, \n",
    "                  x_label='Null values ratio', y_label='MSE', filename='./img/test_missing_regression.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
