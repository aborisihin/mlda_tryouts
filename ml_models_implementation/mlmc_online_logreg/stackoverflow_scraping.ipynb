{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T21:04:06.591516Z",
     "start_time": "2018-08-07T21:04:06.588859Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import requests\n",
    "import json\n",
    "import os.path\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./settings.json', 'r') as settings_file:\n",
    "    settings = json.load(settings_file)\n",
    "\n",
    "print('keys in settings file:')\n",
    "list(settings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed objects count\n",
    "needed_objects = settings['objects_to_scrap']\n",
    "\n",
    "# filepath to store data\n",
    "data_filepath = os.path.join(settings['data_dir'], settings['data_file'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### connection settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = 'https://stackoverflow.com'\n",
    "questions_preview_page = '/questions?page={}&sort=newest'\n",
    "\n",
    "#proxy_string = None\n",
    "proxy_string = 'http://ihodos:987@192.168.5.1:3128'\n",
    "\n",
    "proxy = {'http' : proxy_string, 'https': proxy_string} if proxy_string is not None else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### simple question text preprocess method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_quest(quest_string):\n",
    "    filt = string.punctuation + '\\n'\n",
    "    s = ''.join([symb if symb not in filt else ' ' for symb in quest_string])\n",
    "    s = ' '.join(word for word in s.split() if len(word) > 1)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### receiving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T20:56:16.748588Z",
     "start_time": "2018-08-07T20:56:16.271350Z"
    }
   },
   "outputs": [],
   "source": [
    "preview_pages_limit = (2 * (needed_objects / 50)) + 1\n",
    "\n",
    "processed_previews = 0\n",
    "received_objects = 0\n",
    "\n",
    "with open(data_filepath, 'w', encoding='utf-8', buffering=1) as data_file, \\\n",
    "    tqdm(total=needed_objects) as progress_bar:\n",
    "    \n",
    "    while (received_objects < needed_objects) and (processed_previews < preview_pages_limit):\n",
    "\n",
    "        # get preview page\n",
    "        preview_questions_url = domain + questions_preview_page.format(processed_previews + 1)\n",
    "        preview_questions_req = requests.get(preview_questions_url, proxies=proxy)\n",
    "        processed_previews += 1\n",
    "\n",
    "        # parse previews page and get questions url\n",
    "        preview_questions_soup = BeautifulSoup(preview_questions_req.text, 'lxml')\n",
    "\n",
    "        preview_question_boxes = preview_questions_soup.find_all('div', attrs={'class': 'summary'})\n",
    "\n",
    "        question_urls = []\n",
    "\n",
    "        for box in preview_question_boxes:\n",
    "            url = box.find('a', attrs={'class': 'question-hyperlink'})['href']\n",
    "            question_urls.append(url)\n",
    "\n",
    "        # collect questions and tags\n",
    "        for url in question_urls:\n",
    "\n",
    "            quest_req = requests.get(domain + url, proxies=proxy)\n",
    "            quest_soup = BeautifulSoup(quest_req.text, 'lxml')\n",
    "            quest_text_box = quest_soup.find('div', attrs={'class': 'postcell'})\n",
    "\n",
    "            if quest_text_box is None:\n",
    "                continue\n",
    "\n",
    "            quest_text_elem = quest_text_box.find('div', attrs={'class': 'post-text'})\n",
    "            quest_text = preprocess_quest(quest_text_elem.text.strip())\n",
    "\n",
    "            quest_tag_boxes = quest_text_box.find('div', attrs={'class': 'post-taglist'}).find_all('a')\n",
    "            tags_text = ' '.join([tag.text for tag in quest_tag_boxes])\n",
    "\n",
    "            if (len(quest_text) > 0) and (len(tags_text) > 0):\n",
    "                data_file.write('{}\\t{}\\n'.format(quest_text, tags_text))\n",
    "                received_objects += 1\n",
    "                progress_bar.update(1)\n",
    "\n",
    "            if received_objects >= needed_objects:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
