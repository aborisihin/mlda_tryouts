{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T20:03:36.769942Z",
     "start_time": "2018-08-08T20:03:36.607413Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import requests\n",
    "import json\n",
    "import os.path\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T20:03:37.483690Z",
     "start_time": "2018-08-08T20:03:37.477135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys in settings file:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['data_dir',\n",
       " 'data_file',\n",
       " 'top_tags_count',\n",
       " 'top_tags_file',\n",
       " 'filtered_tmp_file',\n",
       " 'train_size',\n",
       " 'train_file',\n",
       " 'train_labels_file',\n",
       " 'test_file',\n",
       " 'test_labels_file',\n",
       " 'additional_data_dir',\n",
       " 'additional_data_file',\n",
       " 'objects_to_scrap']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./settings.json', 'r') as settings_file:\n",
    "    settings = json.load(settings_file)\n",
    "\n",
    "print('keys in settings file:')\n",
    "list(settings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T20:03:59.354377Z",
     "start_time": "2018-08-08T20:03:59.350851Z"
    }
   },
   "outputs": [],
   "source": [
    "# needed objects count\n",
    "needed_objects = settings['objects_to_scrap']\n",
    "\n",
    "# filepath to store data\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M')\n",
    "data_filepath = os.path.join(settings['additional_data_dir'], \n",
    "                             settings['additional_data_file'].format(timestamp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### connection settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T20:04:00.927892Z",
     "start_time": "2018-08-08T20:04:00.924687Z"
    }
   },
   "outputs": [],
   "source": [
    "domain = 'https://stackoverflow.com'\n",
    "questions_preview_page = '/questions?page={}&sort=newest'\n",
    "\n",
    "proxy_string = None\n",
    "#proxy_string = 'http://ihodos:987@192.168.5.1:3128'\n",
    "\n",
    "proxy = {'http' : proxy_string, 'https': proxy_string} if proxy_string is not None else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### simple question text preprocess method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T20:04:04.616362Z",
     "start_time": "2018-08-08T20:04:04.612641Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_quest(quest_string):\n",
    "    filt = string.punctuation + '\\n'\n",
    "    s = ''.join([symb if symb not in filt else ' ' for symb in quest_string])\n",
    "    s = ' '.join(word for word in s.split() if len(word) > 1)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### receiving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T20:05:28.220415Z",
     "start_time": "2018-08-08T20:04:05.668776Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:22<00:00,  2.03it/s]\n"
     ]
    }
   ],
   "source": [
    "preview_pages_limit = (2 * (needed_objects / 50)) + 1\n",
    "\n",
    "processed_previews = 0\n",
    "received_objects = 0\n",
    "\n",
    "with open(data_filepath, 'w', encoding='utf-8') as data_file, \\\n",
    "    tqdm(total=needed_objects) as progress_bar:\n",
    "    \n",
    "    while (received_objects < needed_objects) and (processed_previews < preview_pages_limit):\n",
    "\n",
    "        # get preview page\n",
    "        preview_questions_url = domain + questions_preview_page.format(processed_previews + 1)\n",
    "        #print('<=', end='')\n",
    "        preview_questions_req = requests.get(preview_questions_url, proxies=proxy)\n",
    "        #print('>', end='')\n",
    "        processed_previews += 1\n",
    "\n",
    "        # parse previews page and get questions url\n",
    "        preview_questions_soup = BeautifulSoup(preview_questions_req.text, 'lxml')\n",
    "\n",
    "        preview_question_boxes = preview_questions_soup.find_all('div', attrs={'class': 'summary'})\n",
    "\n",
    "        question_urls = []\n",
    "\n",
    "        for box in preview_question_boxes:\n",
    "            url = box.find('a', attrs={'class': 'question-hyperlink'})['href']\n",
    "            question_urls.append(url)\n",
    "\n",
    "        # collect questions and tags\n",
    "        for url in question_urls:\n",
    "\n",
    "            #print('<', end='')\n",
    "            quest_req = requests.get(domain + url, proxies=proxy)\n",
    "            #print('>', end='')\n",
    "            quest_soup = BeautifulSoup(quest_req.text, 'lxml')\n",
    "            quest_text_box = quest_soup.find('div', attrs={'class': 'postcell'})\n",
    "\n",
    "            if quest_text_box is None:\n",
    "                continue\n",
    "\n",
    "            quest_text_elem = quest_text_box.find('div', attrs={'class': 'post-text'})\n",
    "            quest_text = preprocess_quest(quest_text_elem.text.strip())\n",
    "\n",
    "            quest_tag_boxes = quest_text_box.find('div', attrs={'class': 'post-taglist'}).find_all('a')\n",
    "            tags_text = ' '.join([tag.text for tag in quest_tag_boxes])\n",
    "\n",
    "            if (len(quest_text) > 0) and (len(tags_text) > 0):\n",
    "                data_file.write('{}\\t{}\\n'.format(quest_text, tags_text))\n",
    "                received_objects += 1\n",
    "                #print(received_objects, end='')\n",
    "                progress_bar.update(1)\n",
    "\n",
    "            if received_objects >= needed_objects:\n",
    "                break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
