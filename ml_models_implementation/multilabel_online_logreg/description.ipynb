{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Логистическая регрессия в задаче классификации текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализована модель multilabel классификации текстов, использующая онлайн обучение (стохастический градиентный спуск с логистической функцией потерь). В качестве примера взят датасет вопросов на stackoverflow, задачей стоит предсказание тегов вопросов.\n",
    "\n",
    "Данные доступны для скачивания по ссылке: https://yadi.sk/d/Vvc4JmX13ZdWvk\n",
    "\n",
    "За основу было взято задание курса OpenDataScience. Автор задания - Павел Нестеров (@mephistopheies)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формат входных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Входные данные представляют собой файл с вопросами пользователей stackoverflow.com. В каждой строке файла содержится текст вопроса и список тегов, разделенные символом табуляции. Теги в списке разделены пробелом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание математической основы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим логистическую регрессию для двух классов $\\{0, 1\\}$. Обозначим вектор признаков объекта как $\\textbf{x}$. Вероятность принадлежности объекта классу $1$, вспомнив теорему Байеса, можно записать как:\n",
    "\n",
    "$$\n",
    "p\\left(c = 1 \\mid \\textbf{x}\\right) = \n",
    "\\dfrac\n",
    "{p\\left(\\textbf{x} \\mid c = 1\\right)p\\left(c = 1\\right)}\n",
    "{p\\left(\\textbf{x}\\right)}\n",
    "$$\n",
    "\n",
    "Воспользуясь формулой полной вероятности, получаем:\n",
    "\n",
    "$$\n",
    "p\\left(c = 1 \\mid \\textbf{x}\\right) = \n",
    "\\dfrac\n",
    "{p\\left(\\textbf{x} \\mid c = 1\\right)p\\left(c = 1\\right)}\n",
    "{p\\left(\\textbf{x} \\mid c = 1\\right)p\\left(c = 1\\right) + p\\left(\\textbf{x} \\mid c = 0\\right)p\\left(c = 0\\right)}\n",
    "$$\n",
    "\n",
    "Введя параметр:\n",
    "\n",
    "$$\n",
    "a = \\log \\dfrac\n",
    "{p\\left(\\textbf{x} \\mid c = 1\\right)p\\left(c = 1\\right)}\n",
    "{p\\left(\\textbf{x} \\mid c = 0\\right)p\\left(c = 0\\right)}\n",
    "$$\n",
    "\n",
    "Мы можем наше выражение переписать в виде:\n",
    "\n",
    "$$\n",
    "p\\left(c = 1 \\mid \\textbf{x}\\right) = \\dfrac{1}{1 + e^{-a}} = \\sigma\\left(a\\right)\n",
    "$$\n",
    "\n",
    "где $\\sigma\\left(a\\right)$ - обозначение функции логистического сигмоида для скалярного аргумента.\n",
    "\n",
    "Значение же параметра $a$ мы моделируем линейной функцией от признаков объекта и параметров модели:\n",
    "\n",
    "$$\n",
    "a = \\sum_{i=0}^M w_i x_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обобщим подход до задачи многоклассовой классификации, то есть у нас есть $K$ классов, к которым может принадлежать объект: $\\{1, 2, ..., K\\}$. Запишем вероятность принадлежности объекта классу $k$:\n",
    "\n",
    "$$\n",
    "p\\left(c = k \\mid \\textbf{x}\\right) = \n",
    "\\dfrac\n",
    "{p\\left(\\textbf{x} \\mid c = k\\right)p\\left(c = k\\right)}\n",
    "{p\\left(\\textbf{x}\\right)} =\n",
    "\\dfrac\n",
    "{p\\left(\\textbf{x} \\mid c = k\\right)p\\left(c = k\\right)}\n",
    "{\\sum_{i=1}^Kp\\left(\\textbf{x} \\mid c = i\\right)p\\left(c = i\\right)}\n",
    "$$\n",
    "\n",
    "Введем параметр:\n",
    "\n",
    "$$\n",
    "z_k = \\log p\\left(\\textbf{x} \\mid c=k \\right) p\\left(c = k\\right)\n",
    "$$\n",
    "\n",
    "Перепишем наше выражение в виде:\n",
    "\n",
    "$$\n",
    "p\\left(c = k \\mid \\textbf{x}\\right) =\n",
    "\\dfrac\n",
    "{e^{z_k}}\n",
    "{\\sum_{i=1}^K e^{z_i}}\n",
    "= \\sigma_k(\\textbf{z})\n",
    "$$\n",
    "\n",
    "где $\\sigma_k$ - $k$-ый компонент функции softmax (обобщение логистической регрессии для многомерного случая) при векторном аргументе.\n",
    "\n",
    "Значение параметра $z_k$ мы моделируем линейной функцией от признаков объекта и параметров модели для класса $k$:\n",
    "\n",
    "$$\n",
    "z_k = \\sum_{i=0}^Mw_{ki}x_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для моделирования искомого распределения будем использовать __[категориальное распределение](https://en.wikipedia.org/wiki/Categorical_distribution)__. Запишем функцию правдоподобия:\n",
    "\n",
    "$$\n",
    "L\\left(\\textbf{y} \\mid \\textbf{p}\\right) = \n",
    "\\prod_{i=1}^{K}p_{i}^{y_{i}} = \n",
    "\\prod_{i=1}^{K}\\sigma_{i}(\\textbf{z})^{y_{i}}\n",
    "$$\n",
    "\n",
    "Поскольку логарифм положительного аргумента монотонно возрастает на всей области определения, то логарифмирование функции правдоподобия не изменит положение ее максимума. Значит, для удобства мы можем воспользоваться логарифмом функции правдоподобия:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\log L = \n",
    "\\log \\left(\\prod_{i=1}^{K}\\sigma_{i}(\\textbf{z})^{y_{i}}\\right) = \n",
    "\\sum_{i=1}^{K}y_{i}\\log \\sigma_{i}(\\textbf{z}) \\rightarrow max\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если домножить на $(-1)$, то получится выражение для __[кросс-энтропии](https://en.wikipedia.org/wiki/Cross_entropy)__ между искомым распределением и распределением оценок обучающей выборки. Правдоподобие мы максимизируем, а кросс-энтропию, соответственно, минимизируем. Для этого будем использовать методы градиентного спуска.\n",
    "\n",
    "$$\n",
    "\\left(-\\mathcal{L}\\right) \\rightarrow min\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продифференцируем $\\mathcal{L}$ по параметрам модели, чтобы получить выражения обновления весов для градиентного спуска. Выражение для дифференцирования мы можем записать в виде:\n",
    "\n",
    "$$\n",
    "\\dfrac {\\partial \\mathcal{L}} {\\partial w_{km}} =\n",
    "\\dfrac {\\partial \\mathcal{L}} {\\partial \\sigma_{k}} \\cdot\n",
    "\\dfrac {\\partial \\sigma_{k}} {\\partial z_{k}} \\cdot\n",
    "\\dfrac {\\partial z_{k}} {\\partial w_{km}}\n",
    "$$\n",
    "\n",
    "Тогда:\n",
    "\n",
    "$$\n",
    "\\dfrac {\\partial \\mathcal{L}} {\\partial \\sigma_{k}} = \n",
    "\\dfrac {\\partial} {\\partial \\sigma_{k}} \\left( \\sum_{i=1}^{K} y_{i} \\cdot \\log \\sigma_{i}\\left( \\textbf{z} \\right) \\right) =\n",
    "\\dfrac {\\partial} {\\partial \\sigma_{k}} \\left( y_{k} \\log \\sigma_{k} \\left( \\textbf{z} \\right) \\right) =\n",
    "\\dfrac {y_{k}} {\\sigma_{k} \\left( \\textbf{z} \\right)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\dfrac {\\partial \\sigma_{k}} {\\partial z_{k}} =\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\dfrac {\\partial z_{k}} {\\partial w_{km}} =\n",
    "\\dfrac {\\partial} {\\partial w_{km}} \\left( \\sum_{i=1}^{M} w_{ki}x_{i} \\right) =\n",
    "\\dfrac {\\partial} {\\partial w_{km}} \\left( w_{km}x_{m} \\right) = x_{m}\n",
    "$$\n",
    "\n",
    "В итоге получаем:\n",
    "\n",
    "$$\n",
    "\\dfrac {\\partial \\mathcal{L}} {\\partial w_{km}} = \n",
    "x_{m} \\left( y_{k} - \\sigma_{k} \\left( \\textbf{z} \\right) \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
