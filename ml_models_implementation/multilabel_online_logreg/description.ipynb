{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Логистическая регрессия в задаче классификации текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализована модель multilabel классификации текстов, использующая онлайн обучение (стохастический градиентный спуск с логистической функцией потерь). В качестве примера взят датасет вопросов на stackoverflow, задачей стоит предсказание тегов вопросов.\n",
    "\n",
    "Данные доступны для скачивания по ссылке: https://yadi.sk/d/Vvc4JmX13ZdWvk\n",
    "\n",
    "За основу было взято задание курса OpenDataScience. Автор задания - Павел Нестеров (@mephistopheies)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формат входных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Входные данные представляют собой файл с вопросами пользователей stackoverflow.com. В каждой строке файла содержится текст вопроса и список тегов, разделенные символом табуляции. Теги в списке разделены пробелом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание математической основы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим логистическую регрессию для двух классов $\\{0, 1\\}$. Обозначим вектор признаков объекта как $\\textbf{x}$. Вероятность принадлежности объекта классу $1$, вспомнив теорему Байеса, можно записать как:\n",
    "\n",
    "$$\n",
    "p\\left(c = 1 \\mid \\textbf{x}\\right) = \n",
    "\\dfrac\n",
    "{p\\left(\\textbf{x} \\mid c = 1\\right)p\\left(c = 1\\right)}\n",
    "{p\\left(\\textbf{x}\\right)}\n",
    "$$\n",
    "\n",
    "Воспользуясь формулой полной вероятности, получаем:\n",
    "\n",
    "$$\n",
    "p\\left(c = 1 \\mid \\textbf{x}\\right) = \n",
    "\\dfrac\n",
    "{p\\left(\\textbf{x} \\mid c = 1\\right)p\\left(c = 1\\right)}\n",
    "{p\\left(\\textbf{x} \\mid c = 1\\right)p\\left(c = 1\\right) + p\\left(\\textbf{x} \\mid c = 0\\right)p\\left(c = 0\\right)}\n",
    "$$\n",
    "\n",
    "Введя параметр:\n",
    "\n",
    "$$\n",
    "a = \\log \\dfrac\n",
    "{p\\left(\\textbf{x} \\mid c = 1\\right)p\\left(c = 1\\right)}\n",
    "{p\\left(\\textbf{x} \\mid c = 0\\right)p\\left(c = 0\\right)}\n",
    "$$\n",
    "\n",
    "Мы можем наше выражение переписать в виде:\n",
    "\n",
    "$$\n",
    "p\\left(c = 1 \\mid \\textbf{x}\\right) = \\dfrac{1}{1 + e^{-a}} = \\sigma\\left(a\\right)\n",
    "$$\n",
    "\n",
    "где $\\sigma\\left(a\\right)$ - обозначение функции логистического сигмоида для скалярного аргумента.\n",
    "\n",
    "Значение же параметра $a$ мы моделируем линейной функцией от признаков объекта и параметров модели:\n",
    "\n",
    "$$\n",
    "a = \\sum_{i=0}^M w_i x_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обобщим подход до задачи многоклассовой классификации, то есть у нас есть $K$ классов, к которым может принадлежать объект: $\\{1, 2, ..., K\\}$. Запишем вероятность принадлежности объекта классу $k$:\n",
    "\n",
    "$$\n",
    "p\\left(c = k \\mid \\textbf{x}\\right) = \n",
    "\\dfrac\n",
    "{p\\left(\\textbf{x} \\mid c = k\\right)p\\left(c = k\\right)}\n",
    "{p\\left(\\textbf{x}\\right)} =\n",
    "\\dfrac\n",
    "{p\\left(\\textbf{x} \\mid c = k\\right)p\\left(c = k\\right)}\n",
    "{\\sum_{i=1}^Kp\\left(\\textbf{x} \\mid c = i\\right)p\\left(c = i\\right)}\n",
    "$$\n",
    "\n",
    "Введем параметр:\n",
    "\n",
    "$$\n",
    "z_k = \\log p\\left(\\textbf{x} \\mid c=k \\right) p\\left(c = k\\right)\n",
    "$$\n",
    "\n",
    "Перепишем наше выражение в виде:\n",
    "\n",
    "$$\n",
    "p\\left(c = k \\mid \\textbf{x}\\right) =\n",
    "\\dfrac\n",
    "{e^{z_k}}\n",
    "{\\sum_{i=1}^K e^{z_i}}\n",
    "= \\sigma_k(\\textbf{z})\n",
    "$$\n",
    "\n",
    "где $\\sigma_k$ - $k$-ый компонент функции softmax (обобщение логистической регрессии для многомерного случая) при векторном аргументе.\n",
    "\n",
    "Значение параметра $z_k$ мы моделируем линейной функцией от признаков объекта (размерности M) и параметров модели для класса $k$:\n",
    "\n",
    "$$\n",
    "z_k = \\sum_{i=1}^Mw_{ki}x_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для моделирования искомого распределения будем использовать __[категориальное распределение](https://en.wikipedia.org/wiki/Categorical_distribution)__. Запишем функцию правдоподобия:\n",
    "\n",
    "$$\n",
    "L\\left(\\textbf{y} \\mid \\textbf{p}\\right) = \n",
    "\\prod_{i=1}^{K}p_{i}^{y_{i}} = \n",
    "\\prod_{i=1}^{K}\\sigma_{i}(\\textbf{z})^{y_{i}}\n",
    "$$\n",
    "\n",
    "Поскольку логарифм положительного аргумента монотонно возрастает на всей области определения, то логарифмирование функции правдоподобия не изменит положение ее максимума. Значит, для удобства мы можем воспользоваться логарифмом функции правдоподобия:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\log L = \n",
    "\\log \\left(\\prod_{i=1}^{K}\\sigma_{i}(\\textbf{z})^{y_{i}}\\right) = \n",
    "\\sum_{i=1}^{K}y_{i}\\log \\sigma_{i}(\\textbf{z}) \\rightarrow max\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если домножить на $(-1)$, то получится выражение для __[кросс-энтропии](https://en.wikipedia.org/wiki/Cross_entropy)__ между искомым распределением и распределением оценок обучающей выборки. Правдоподобие мы максимизируем, а кросс-энтропию, соответственно, минимизируем.\n",
    "\n",
    "$$\n",
    "H = \\left(-\\mathcal{L}\\right) \\rightarrow min\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для этого будем использовать методы градиентного спуска. Необходимо вывести выражение для компонент вектора градиента кросс-энтропии:\n",
    "\n",
    "$$\n",
    "\\dfrac {\\partial H} {\\partial w_{km}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим следующие частные производные:\n",
    "\n",
    "$$\n",
    "\\dfrac {\\partial H} {\\partial \\sigma_{k}} =\n",
    "\\dfrac {\\partial} {\\partial \\sigma_{k}} \\left( -\\sum_{i=1}^{K} y_i \\log \\sigma_i \\right) =\n",
    "- \\dfrac {y_k} {\\sigma_k}\n",
    "$$\n",
    "<br><br>\n",
    "$$\n",
    "\\dfrac {\\partial \\sigma_i} {\\partial z_k} = \n",
    "\\dfrac {\\partial} {\\partial z_k} \\left( \\dfrac {e^{z_i}} {\\sum_{j=1}^{K} e^{z_j}} \\right) =\n",
    "\\left \\{ \\begin{array}{lcl} \n",
    "\\dfrac {1} {\\left( \\sum_{j=1}^{K}e^{z_j} \\right)^2 } \\left( e^{z_k} \\sum_{j=1}^{K}e^{z_j} - e^{z_k} \\cdot e^{z_k} \\right) &=&\n",
    "\\sigma_k \\left( 1 - \\sigma_k \\right) && (i=k)\n",
    "\\\\ \n",
    "\\dfrac {1} {\\left( \\sum_{j=1}^{K}e^{z_j} \\right)^2 } \\left( -e^{z_i} \\cdot e^{z_k} \\right) &=&\n",
    "- \\sigma_i \\sigma_k && (i \\neq k)\n",
    "\\end{array} \\right.\n",
    "$$\n",
    "<br><br>\n",
    "$$\n",
    "\\dfrac {\\partial z_k} {\\partial w_{km}} =\n",
    "\\dfrac {\\partial} {\\partial w_{km}} \\left( \\sum_{j=1}^{M} w_{kj}x_j \\right) = x_m\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем записать:\n",
    "\n",
    "$$\n",
    "\\dfrac {\\partial H} {\\partial z_k} = \n",
    "\\sum_{i=1}^{K} \\dfrac {\\partial H} {\\partial \\sigma_i} \\dfrac {\\partial \\sigma_i} {\\partial z_k} =\n",
    "\\dfrac {\\partial H} {\\partial \\sigma_k} \\dfrac {\\partial \\sigma_k} {\\partial z_k} +\n",
    "\\sum_{i \\neq k} \\dfrac {\\partial H} {\\partial \\sigma_i} \\dfrac {\\partial \\sigma_i} {\\partial z_k} =\n",
    "-y_k \\left( 1- \\sigma_k \\right) + \\sum_{i \\neq k} y_i \\sigma_k =\n",
    "-y_k + \\sigma_k \\sum_{i} y_i =\n",
    "\\sigma_k - y_k\n",
    "$$\n",
    "<br><br>\n",
    "$$\n",
    "\\dfrac {\\partial H} {\\partial w_{km}} =\n",
    "\\sum_{i=1}^{K} \\dfrac {\\partial H} {\\partial z_i} \\dfrac {\\partial z_i} {\\partial w_{km}} =\n",
    "x_m \\left( \\sigma_k - y_k \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
